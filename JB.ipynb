{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "JB.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('predict.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TirpsaEcdgeP",
    "outputId": "8f39ea24-5b20-4367-d849-60f0c8187f9a"
   },
   "source": [
    "data"
   ],
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "     recency  topic_rank  diversity  authors_mean_rank  authors_mean_hindex  \\\n0         16         1.0  -0.425436              500.0                  1.0   \n1          8         7.0  -0.571967              134.0                  1.0   \n2         15        19.0  -0.859644              235.0                  1.0   \n3          6         4.0  -1.054999             1124.0                  1.0   \n4         14         2.0  -0.476697              346.0                  1.0   \n..       ...         ...        ...                ...                  ...   \n474       25         6.0  -0.330948              528.0                  0.0   \n475        6        12.0  -1.493480             2145.0                  0.0   \n476       24        17.0  -1.466320              551.0                  0.0   \n477       24         6.0  -1.556737              551.0                  0.0   \n478       23         9.0  -0.283168              602.0                  0.0   \n\n     authors_mean_gindex  authors_mean_sociality  authors_mean_pagerank  \\\n0                    1.0                     6.0                    NaN   \n1                    1.0                     6.0                    NaN   \n2                    1.0                     5.0                    NaN   \n3                    1.0                    10.0                    NaN   \n4                    1.0                     2.0                    NaN   \n..                   ...                     ...                    ...   \n474                  0.0                     6.0                    NaN   \n475                  0.0                     1.0                    NaN   \n476                  0.0                     4.0                    NaN   \n477                  0.0                     0.0                    NaN   \n478                  0.0                     0.0                    NaN   \n\n     authors_mean_productivity  journal_pagerank  journal_rank  title_len  \\\n0                          NaN               NaN         101.0         66   \n1                          NaN               NaN          24.0         59   \n2                          NaN               NaN          49.0        169   \n3                          NaN               NaN         185.0        130   \n4                          NaN               NaN          72.0        100   \n..                         ...               ...           ...        ...   \n474                        NaN               NaN         140.0         62   \n475                        NaN               NaN         416.0         45   \n476                        NaN               NaN         146.0         84   \n477                        NaN               NaN         146.0         56   \n478                        NaN               NaN         155.0         90   \n\n     abstract_len  n_authors    c5  log_authors_mean_sociality  \n0            1653          7   1.0                    1.945910  \n1            1527          7  32.0                    1.945910  \n2            1554          6   5.0                    1.791759  \n3            2121         11   7.0                    2.397895  \n4             432          3   7.0                    1.098612  \n..            ...        ...   ...                         ...  \n474           645          7   0.0                    1.945910  \n475           714          2   0.0                    0.693147  \n476             0          5   0.0                    1.609438  \n477             0          1   0.0                    0.000000  \n478           476          1   0.0                    0.000000  \n\n[479 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recency</th>\n      <th>topic_rank</th>\n      <th>diversity</th>\n      <th>authors_mean_rank</th>\n      <th>authors_mean_hindex</th>\n      <th>authors_mean_gindex</th>\n      <th>authors_mean_sociality</th>\n      <th>authors_mean_pagerank</th>\n      <th>authors_mean_productivity</th>\n      <th>journal_pagerank</th>\n      <th>journal_rank</th>\n      <th>title_len</th>\n      <th>abstract_len</th>\n      <th>n_authors</th>\n      <th>c5</th>\n      <th>log_authors_mean_sociality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>1.0</td>\n      <td>-0.425436</td>\n      <td>500.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>101.0</td>\n      <td>66</td>\n      <td>1653</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>1.945910</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>7.0</td>\n      <td>-0.571967</td>\n      <td>134.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>59</td>\n      <td>1527</td>\n      <td>7</td>\n      <td>32.0</td>\n      <td>1.945910</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>19.0</td>\n      <td>-0.859644</td>\n      <td>235.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>49.0</td>\n      <td>169</td>\n      <td>1554</td>\n      <td>6</td>\n      <td>5.0</td>\n      <td>1.791759</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>4.0</td>\n      <td>-1.054999</td>\n      <td>1124.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>185.0</td>\n      <td>130</td>\n      <td>2121</td>\n      <td>11</td>\n      <td>7.0</td>\n      <td>2.397895</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>2.0</td>\n      <td>-0.476697</td>\n      <td>346.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>72.0</td>\n      <td>100</td>\n      <td>432</td>\n      <td>3</td>\n      <td>7.0</td>\n      <td>1.098612</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>474</th>\n      <td>25</td>\n      <td>6.0</td>\n      <td>-0.330948</td>\n      <td>528.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>140.0</td>\n      <td>62</td>\n      <td>645</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.945910</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>6</td>\n      <td>12.0</td>\n      <td>-1.493480</td>\n      <td>2145.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>416.0</td>\n      <td>45</td>\n      <td>714</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.693147</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>24</td>\n      <td>17.0</td>\n      <td>-1.466320</td>\n      <td>551.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>146.0</td>\n      <td>84</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.609438</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>24</td>\n      <td>6.0</td>\n      <td>-1.556737</td>\n      <td>551.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>146.0</td>\n      <td>56</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>23</td>\n      <td>9.0</td>\n      <td>-0.283168</td>\n      <td>602.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>155.0</td>\n      <td>90</td>\n      <td>476</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndtlsjYtdjTl",
    "outputId": "66e1fff6-9ea4-4e96-c31f-1ce0c61a847d"
   },
   "source": [
    "data.isnull().sum()"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "recency                         0\ntopic_rank                      0\ndiversity                       0\nauthors_mean_rank               6\nauthors_mean_hindex             6\nauthors_mean_gindex             6\nauthors_mean_sociality          6\nauthors_mean_pagerank         479\nauthors_mean_productivity     479\njournal_pagerank              479\njournal_rank                   39\ntitle_len                       0\nabstract_len                    0\nn_authors                       0\nc5                              0\nlog_authors_mean_sociality      6\ndtype: int64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kTHkQ-5fOFD"
   },
   "source": [
    "Видим, что в датасете у нас три пустых колонки, можно их удалить из датасета. Так же authors_mean_sociality и log_authors_mean_sociality являются зависимыми признаками, значит можно избавиться от одного из них"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NY3sj8OVfMva"
   },
   "source": [
    "data = data.drop(columns=['journal_pagerank','authors_mean_productivity','authors_mean_pagerank','log_authors_mean_sociality'])"
   ],
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxgi182lhIFo"
   },
   "source": [
    "Выведем список всех строк с NaN значением у признака/признаков"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Xnqd0Pv1fiPY",
    "outputId": "8f800478-72b8-4495-d229-a3be005271d0"
   },
   "source": [
    "data[data.isna().any(axis = 1)]\n",
    "\n"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "     recency  topic_rank  diversity  authors_mean_rank  authors_mean_hindex  \\\n8          5         3.0  -1.464084             1282.0                1.000   \n15        13        20.0  -0.178360              326.0                1.000   \n19        14        19.0  -0.647923             1015.0                1.000   \n22         8         2.0  -1.390480               94.0                1.000   \n23         5         3.0  -1.224150              219.0                1.000   \n56         7         6.0  -1.367137             1174.0                1.000   \n81         6        14.0  -0.296585             1469.0                1.000   \n85        21         4.0  -0.120934              106.0                1.000   \n97         5        12.0  -0.974201             1935.0                1.000   \n107        6         7.0  -0.066097             1628.0                1.000   \n109        9         3.0  -0.099415              379.0                1.000   \n142        8         2.0  -0.104002              630.0                1.000   \n154        9        14.0  -0.071078              333.0                1.000   \n175       10         7.0  -0.142626              607.0                1.000   \n190       16         6.0  -0.075675              224.0                1.000   \n198        7        14.0  -0.090506             1059.0                1.000   \n227        7         3.0  -0.164493             1775.0                1.000   \n230        6        19.0  -0.142626             1776.0                1.000   \n243       10        15.0  -1.531056              197.0                1.000   \n257        5        17.0  -0.080949              208.0                1.000   \n261        8         4.0  -0.752599             1219.0                1.000   \n278        9         7.0  -1.658970              949.0                1.000   \n279        6         3.0  -1.164230              589.0                1.000   \n290        5        15.0  -0.056685             1444.5                1.125   \n299        5        13.0  -0.106469             1150.0                1.000   \n308       12        19.0  -1.558446              118.0                1.000   \n313        7         3.0  -1.385588              621.0                1.000   \n321        6        20.0  -0.174664              458.0                1.000   \n331        5        18.0  -0.796707             1935.0                1.000   \n334        9         9.0  -1.112809              570.0                1.000   \n336        8         9.0  -0.199657              217.0                1.000   \n355       11        10.0  -0.824070              395.0                1.000   \n379        5         2.0  -0.414833              596.0                1.000   \n390       12        10.0  -0.706425             1267.0                1.000   \n393        9         5.0  -0.497538              949.0                1.000   \n397        7         2.0  -0.124345              468.0                1.000   \n399       13         5.0  -0.138085             1371.0                0.000   \n418       15        16.0  -1.247485                NaN                  NaN   \n422       22         5.0  -1.045666                NaN                  NaN   \n423       13        10.0  -2.090505                NaN                  NaN   \n432        6        13.0  -0.233729             2145.0                0.000   \n433        5        16.0  -0.806385             2336.0                0.000   \n451       25        17.0  -0.317449                NaN                  NaN   \n458       17        15.0  -2.090505                NaN                  NaN   \n464        6        15.0  -0.796709                NaN                  NaN   \n\n     authors_mean_gindex  authors_mean_sociality  journal_rank  title_len  \\\n8                  1.000                  3.0000           NaN         44   \n15                 1.000                  2.0000           NaN        169   \n19                 1.000                  0.0000           NaN         32   \n22                 1.000                  8.0000           NaN        107   \n23                 1.000                  2.0000           NaN        101   \n56                 1.000                  2.0000           NaN        165   \n81                 1.000                  7.0000           NaN        108   \n85                 1.000                 10.0000           NaN         91   \n97                 1.000                  5.0000           NaN         64   \n107                1.000                  3.0000           NaN        161   \n109                1.000                  1.0000           NaN        108   \n142                1.000                  3.0000           NaN         65   \n154                1.000                  5.0000           NaN        117   \n175                1.000                  8.0000           NaN         99   \n190                1.000                  6.0000           NaN        112   \n198                1.000                  1.0000           NaN         96   \n227                1.000                  5.0000           NaN         93   \n230                1.000                  4.0000           NaN        114   \n243                1.000                  8.0000           NaN         73   \n257                1.000                  4.0000           NaN        111   \n261                1.000                  5.0000           NaN         79   \n278                1.000                  1.0000           NaN         70   \n279                1.000                 13.0000           NaN        162   \n290                1.125                  6.8125           NaN        118   \n299                1.000                  0.0000           NaN         54   \n308                1.000                  8.0000           NaN        150   \n313                1.000                  4.0000           NaN         89   \n321                1.000                  5.0000           NaN         86   \n331                1.000                  4.0000           NaN         85   \n334                1.000                  3.0000           NaN         84   \n336                1.000                  1.0000           NaN         86   \n355                1.000                  0.0000           NaN         46   \n379                1.000                  7.0000           NaN        105   \n390                1.000                  0.0000           NaN        108   \n393                1.000                  5.0000           NaN        125   \n397                1.000                  4.0000           NaN        112   \n399                0.000                  1.0000           NaN         48   \n418                  NaN                     NaN         270.0         46   \n422                  NaN                     NaN         165.0        119   \n423                  NaN                     NaN         310.0         51   \n432                0.000                  2.0000           NaN        109   \n433                0.000                  1.0000           NaN         59   \n451                  NaN                     NaN         140.0         64   \n458                  NaN                     NaN         236.0         38   \n464                  NaN                     NaN         416.0         22   \n\n     abstract_len  n_authors    c5  \n8            1191          4   8.0  \n15           1323          3   9.0  \n19            275          1   2.0  \n22           1987          9  46.0  \n23           1147          3  49.0  \n56           1722          3   5.0  \n81           2407          8   5.0  \n85           1350         11   7.0  \n97            341          6   2.0  \n107          2409          4   3.0  \n109          1648          2  13.0  \n142          1791          4   7.0  \n154          2387          6  19.0  \n175          1169          9  11.0  \n190          2128          7   7.0  \n198          1640          2   9.0  \n227          1389          6   1.0  \n230          1112          5   2.0  \n243          2113          9  18.0  \n257          2491          5  50.0  \n261           661          6   3.0  \n278           149          2   2.0  \n279          2326         14  16.0  \n290          2355          8   5.0  \n299          1629          1  10.0  \n308          1899          9  12.0  \n313          1429          5  13.0  \n321          1379          6  24.0  \n331          1065          5   2.0  \n334          2522          4   7.0  \n336           575          2  32.0  \n355           844          1   5.0  \n379          1959          8  21.0  \n390          1900          1   1.0  \n393          2187          6   1.0  \n397          1223          5  19.0  \n399          1241          2   0.0  \n418             0          1   0.0  \n422             0          1   0.0  \n423             0          1   0.0  \n432          1097          3   0.0  \n433          3655          2   0.0  \n451           657          1   0.0  \n458             0          1   0.0  \n464           218          1   0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recency</th>\n      <th>topic_rank</th>\n      <th>diversity</th>\n      <th>authors_mean_rank</th>\n      <th>authors_mean_hindex</th>\n      <th>authors_mean_gindex</th>\n      <th>authors_mean_sociality</th>\n      <th>journal_rank</th>\n      <th>title_len</th>\n      <th>abstract_len</th>\n      <th>n_authors</th>\n      <th>c5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>5</td>\n      <td>3.0</td>\n      <td>-1.464084</td>\n      <td>1282.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>3.0000</td>\n      <td>NaN</td>\n      <td>44</td>\n      <td>1191</td>\n      <td>4</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>13</td>\n      <td>20.0</td>\n      <td>-0.178360</td>\n      <td>326.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>2.0000</td>\n      <td>NaN</td>\n      <td>169</td>\n      <td>1323</td>\n      <td>3</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>14</td>\n      <td>19.0</td>\n      <td>-0.647923</td>\n      <td>1015.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>32</td>\n      <td>275</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>8</td>\n      <td>2.0</td>\n      <td>-1.390480</td>\n      <td>94.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>8.0000</td>\n      <td>NaN</td>\n      <td>107</td>\n      <td>1987</td>\n      <td>9</td>\n      <td>46.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>5</td>\n      <td>3.0</td>\n      <td>-1.224150</td>\n      <td>219.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>2.0000</td>\n      <td>NaN</td>\n      <td>101</td>\n      <td>1147</td>\n      <td>3</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>7</td>\n      <td>6.0</td>\n      <td>-1.367137</td>\n      <td>1174.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>2.0000</td>\n      <td>NaN</td>\n      <td>165</td>\n      <td>1722</td>\n      <td>3</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>6</td>\n      <td>14.0</td>\n      <td>-0.296585</td>\n      <td>1469.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>108</td>\n      <td>2407</td>\n      <td>8</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>21</td>\n      <td>4.0</td>\n      <td>-0.120934</td>\n      <td>106.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>10.0000</td>\n      <td>NaN</td>\n      <td>91</td>\n      <td>1350</td>\n      <td>11</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>5</td>\n      <td>12.0</td>\n      <td>-0.974201</td>\n      <td>1935.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>5.0000</td>\n      <td>NaN</td>\n      <td>64</td>\n      <td>341</td>\n      <td>6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>6</td>\n      <td>7.0</td>\n      <td>-0.066097</td>\n      <td>1628.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>3.0000</td>\n      <td>NaN</td>\n      <td>161</td>\n      <td>2409</td>\n      <td>4</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>9</td>\n      <td>3.0</td>\n      <td>-0.099415</td>\n      <td>379.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>108</td>\n      <td>1648</td>\n      <td>2</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>8</td>\n      <td>2.0</td>\n      <td>-0.104002</td>\n      <td>630.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>3.0000</td>\n      <td>NaN</td>\n      <td>65</td>\n      <td>1791</td>\n      <td>4</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>9</td>\n      <td>14.0</td>\n      <td>-0.071078</td>\n      <td>333.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>5.0000</td>\n      <td>NaN</td>\n      <td>117</td>\n      <td>2387</td>\n      <td>6</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>10</td>\n      <td>7.0</td>\n      <td>-0.142626</td>\n      <td>607.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>8.0000</td>\n      <td>NaN</td>\n      <td>99</td>\n      <td>1169</td>\n      <td>9</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>16</td>\n      <td>6.0</td>\n      <td>-0.075675</td>\n      <td>224.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>6.0000</td>\n      <td>NaN</td>\n      <td>112</td>\n      <td>2128</td>\n      <td>7</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>7</td>\n      <td>14.0</td>\n      <td>-0.090506</td>\n      <td>1059.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>96</td>\n      <td>1640</td>\n      <td>2</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>7</td>\n      <td>3.0</td>\n      <td>-0.164493</td>\n      <td>1775.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>5.0000</td>\n      <td>NaN</td>\n      <td>93</td>\n      <td>1389</td>\n      <td>6</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>230</th>\n      <td>6</td>\n      <td>19.0</td>\n      <td>-0.142626</td>\n      <td>1776.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>4.0000</td>\n      <td>NaN</td>\n      <td>114</td>\n      <td>1112</td>\n      <td>5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>10</td>\n      <td>15.0</td>\n      <td>-1.531056</td>\n      <td>197.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>8.0000</td>\n      <td>NaN</td>\n      <td>73</td>\n      <td>2113</td>\n      <td>9</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>5</td>\n      <td>17.0</td>\n      <td>-0.080949</td>\n      <td>208.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>4.0000</td>\n      <td>NaN</td>\n      <td>111</td>\n      <td>2491</td>\n      <td>5</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>8</td>\n      <td>4.0</td>\n      <td>-0.752599</td>\n      <td>1219.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>5.0000</td>\n      <td>NaN</td>\n      <td>79</td>\n      <td>661</td>\n      <td>6</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>9</td>\n      <td>7.0</td>\n      <td>-1.658970</td>\n      <td>949.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>70</td>\n      <td>149</td>\n      <td>2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>6</td>\n      <td>3.0</td>\n      <td>-1.164230</td>\n      <td>589.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>162</td>\n      <td>2326</td>\n      <td>14</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>5</td>\n      <td>15.0</td>\n      <td>-0.056685</td>\n      <td>1444.5</td>\n      <td>1.125</td>\n      <td>1.125</td>\n      <td>6.8125</td>\n      <td>NaN</td>\n      <td>118</td>\n      <td>2355</td>\n      <td>8</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>5</td>\n      <td>13.0</td>\n      <td>-0.106469</td>\n      <td>1150.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>54</td>\n      <td>1629</td>\n      <td>1</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>308</th>\n      <td>12</td>\n      <td>19.0</td>\n      <td>-1.558446</td>\n      <td>118.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>8.0000</td>\n      <td>NaN</td>\n      <td>150</td>\n      <td>1899</td>\n      <td>9</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>313</th>\n      <td>7</td>\n      <td>3.0</td>\n      <td>-1.385588</td>\n      <td>621.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>4.0000</td>\n      <td>NaN</td>\n      <td>89</td>\n      <td>1429</td>\n      <td>5</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>6</td>\n      <td>20.0</td>\n      <td>-0.174664</td>\n      <td>458.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>5.0000</td>\n      <td>NaN</td>\n      <td>86</td>\n      <td>1379</td>\n      <td>6</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>5</td>\n      <td>18.0</td>\n      <td>-0.796707</td>\n      <td>1935.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>4.0000</td>\n      <td>NaN</td>\n      <td>85</td>\n      <td>1065</td>\n      <td>5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>9</td>\n      <td>9.0</td>\n      <td>-1.112809</td>\n      <td>570.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>3.0000</td>\n      <td>NaN</td>\n      <td>84</td>\n      <td>2522</td>\n      <td>4</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>336</th>\n      <td>8</td>\n      <td>9.0</td>\n      <td>-0.199657</td>\n      <td>217.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>86</td>\n      <td>575</td>\n      <td>2</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>11</td>\n      <td>10.0</td>\n      <td>-0.824070</td>\n      <td>395.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>46</td>\n      <td>844</td>\n      <td>1</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>5</td>\n      <td>2.0</td>\n      <td>-0.414833</td>\n      <td>596.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>105</td>\n      <td>1959</td>\n      <td>8</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>12</td>\n      <td>10.0</td>\n      <td>-0.706425</td>\n      <td>1267.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>108</td>\n      <td>1900</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>9</td>\n      <td>5.0</td>\n      <td>-0.497538</td>\n      <td>949.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>5.0000</td>\n      <td>NaN</td>\n      <td>125</td>\n      <td>2187</td>\n      <td>6</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>7</td>\n      <td>2.0</td>\n      <td>-0.124345</td>\n      <td>468.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>4.0000</td>\n      <td>NaN</td>\n      <td>112</td>\n      <td>1223</td>\n      <td>5</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>13</td>\n      <td>5.0</td>\n      <td>-0.138085</td>\n      <td>1371.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>48</td>\n      <td>1241</td>\n      <td>2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>418</th>\n      <td>15</td>\n      <td>16.0</td>\n      <td>-1.247485</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>270.0</td>\n      <td>46</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>22</td>\n      <td>5.0</td>\n      <td>-1.045666</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>165.0</td>\n      <td>119</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>13</td>\n      <td>10.0</td>\n      <td>-2.090505</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>310.0</td>\n      <td>51</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>6</td>\n      <td>13.0</td>\n      <td>-0.233729</td>\n      <td>2145.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.0000</td>\n      <td>NaN</td>\n      <td>109</td>\n      <td>1097</td>\n      <td>3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>5</td>\n      <td>16.0</td>\n      <td>-0.806385</td>\n      <td>2336.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>59</td>\n      <td>3655</td>\n      <td>2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>451</th>\n      <td>25</td>\n      <td>17.0</td>\n      <td>-0.317449</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>140.0</td>\n      <td>64</td>\n      <td>657</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>458</th>\n      <td>17</td>\n      <td>15.0</td>\n      <td>-2.090505</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>236.0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>464</th>\n      <td>6</td>\n      <td>15.0</td>\n      <td>-0.796709</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>416.0</td>\n      <td>22</td>\n      <td>218</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsB9PRLUiC8D"
   },
   "source": [
    "Попробуем поработать с датасетом, где NaN значения заполнены нулями"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4155Rxz9fojN"
   },
   "source": [
    "data_zeros = data.fillna(0)"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChKPYv6MhcbO",
    "outputId": "83931174-bad0-4759-9953-3af3b43896be"
   },
   "source": [
    "data_zeros.isnull().sum()"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "recency                   0\ntopic_rank                0\ndiversity                 0\nauthors_mean_rank         0\nauthors_mean_hindex       0\nauthors_mean_gindex       0\nauthors_mean_sociality    0\njournal_rank              0\ntitle_len                 0\nabstract_len              0\nn_authors                 0\nc5                        0\ndtype: int64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVl6C-IPi2D2"
   },
   "source": [
    "Так как все признаки лежат в разных диапазонах значений, не лишним будет нормализовать их"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mnacSBnPi-l3"
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C0mmRKD7jUzd"
   },
   "source": [
    "scaler = StandardScaler()\n",
    "X = data_zeros.drop(columns='c5')\n",
    "y = data_zeros['c5']\n",
    "X = scaler.fit_transform(X)"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFOw3z0UiLTg"
   },
   "source": [
    "Разобьем наш датасет на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMNbCOcPoiBi"
   },
   "source": [
    "Чтобы зафиксировать разбиение и результат моделей, воспользуемся np.random.seed"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pveVDR-wounr"
   },
   "source": [
    "np.random.seed(21)"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SHCywMcXiOuS"
   },
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nTeQBAn8iTGi"
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HURULuaCkE8W"
   },
   "source": [
    "# Baselines (LinearRegression, RandomForestRegressor, GradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KDeE5MZKkl_7"
   },
   "source": [
    "from sklearn.metrics import r2_score\n"
   ],
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcPrTFLGkSgI"
   },
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mkx_R6lkkGZA"
   },
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ],
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SG8yxnsOkg9B",
    "outputId": "2efc583c-7271-491e-b1a7-73d6eb4c1037"
   },
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sd0Pdfsqkif4",
    "outputId": "b8ae4ae4-7c4b-4b8f-c0c2-c0ae3043a50e"
   },
   "source": [
    "r2_score(y_test,model.predict(X_test))"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "0.48039830719833254"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCVV0jo0k6G5"
   },
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fdBtmvz6k7eL"
   },
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8rfhDT_k_94",
    "outputId": "39d83563-c8e5-4e3a-98b6-2c541c17f3a7"
   },
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,y_train)"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor()"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lq_gL1lHlFYk",
    "outputId": "d581939e-cfaf-4113-c24b-bdb469fc1ab1"
   },
   "source": [
    "r2_score(y_test,model.predict(X_test))"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0.48548502012254646"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gu7mJZGVlpNi"
   },
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Di9NnM6JluOZ"
   },
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7qdHsW-mLGw",
    "outputId": "179b6254-81de-4534-f182-78f148431c45"
   },
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train,y_train)"
   ],
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingRegressor()"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEK4_MV3mP58",
    "outputId": "f433039d-7024-48b9-b8dc-d08fbd0decee"
   },
   "source": [
    "r2_score(y_test,model.predict(X_test))"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6668230077909751"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFrkzCxIn8vE"
   },
   "source": [
    "Без настройки гиперпараметров из моделей лучше всего справился GradientBoostingRegressor, воспользуемся модулем sklearn GridSearchCV для нахождения лучших гиперпараметров для нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JGlvEFr8oPvw"
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "izcoMHgDpZY7"
   },
   "source": [
    "parameters = {'loss': ('ls', 'lad', 'huber', 'quantile'),\n",
    "              'learning_rate': [0.1,0.07,0.05,0.04,0.03,0.02],\n",
    "              'n_estimators':[500,600,700,900]}"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FlyKqQtjrj2W"
   },
   "source": [
    "clf = GridSearchCV(model,parameters,'r2')"
   ],
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasya\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass scoring=r2 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ld6YZXRMrpNT",
    "outputId": "cf58f4ed-a8d0-482c-8aa6-0f81c53562be"
   },
   "source": [
    "clf.fit(X_train,y_train)"
   ],
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=GradientBoostingRegressor(),\n             param_grid={'learning_rate': [0.1, 0.07, 0.05, 0.04, 0.03, 0.02],\n                         'loss': ('ls', 'lad', 'huber', 'quantile'),\n                         'n_estimators': [500, 600, 700, 900]},\n             scoring='r2')"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9dQI1-1spU_",
    "outputId": "e96440d5-9d31-4916-954d-dda0c846359d"
   },
   "source": [
    "clf.best_params_"
   ],
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "{'learning_rate': 0.1, 'loss': 'lad', 'n_estimators': 900}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PX-zLjRXrxZ6",
    "outputId": "831fd75c-521d-4df0-c155-16b28909a02a"
   },
   "source": [
    "r2_score(y_test,clf.predict(X_test))"
   ],
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7700327598416694"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Осталось посмотреть на важнейшие признаки для нашей модели"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nLCNF11czQwY"
   },
   "source": [
    "feature_importance = clf.best_estimator_.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, np.array(data.columns)[sorted_idx])\n",
    "plt.title('Feature Importance')\n"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Feature Importance')"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что наиболее важными признаками для модели являются: authors_mean_hindex и authors_mean_gindex.\n",
    "И это логически правильно, ведь h-index и g-index как раз служат метрикой продуктивности и цитируемости автора.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Мы работали с датасетом, где NaN значения были заполнены нулями, попробуем теперь использовать interpolate (метод, который использует интерполяцию для отсутствующих значений)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "data_interpolated = data.interpolate('cubicspline')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "recency                   0\ntopic_rank                0\ndiversity                 0\nauthors_mean_rank         0\nauthors_mean_hindex       0\nauthors_mean_gindex       0\nauthors_mean_sociality    0\njournal_rank              0\ntitle_len                 0\nabstract_len              0\nn_authors                 0\nc5                        0\ndtype: int64"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_interpolated.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "И повторим те же действия, что и предыдущим датасетом (нормализуем и разобьем на две выборки)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y = data_interpolated['c5']\n",
    "X = data_interpolated.drop(columns='c5')\n",
    "X = scaler.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=GradientBoostingRegressor(),\n             param_grid={'learning_rate': [0.1, 0.07, 0.05, 0.04, 0.03, 0.02],\n                         'loss': ('ls', 'lad', 'huber', 'quantile'),\n                         'n_estimators': [500, 600, 700, 900]},\n             scoring='r2')"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6938283777637873"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,clf.predict(X_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "К сожалению, качество модели улучшить не получилось.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}